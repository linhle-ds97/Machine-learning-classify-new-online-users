{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280203ce-5469-43e1-8b94-cc75ad7dea17",
   "metadata": {},
   "source": [
    "# DESCRIPTION: \n",
    "This script develops several machine learning models including Decision Tree, Random Forest, Gradient Descending Classifier, XGBoost.\n",
    "- Objective: To classify two types of users of a specific online product (Paid Online users vs Organic users) based on different features of users behaviors such as adblock is on/off, total online time per day, country.\n",
    "\n",
    "- Purpose: Classifying users into correct categories helps the company to measure the effectiveness of Paid Marketing campaign in terms of getting more Paid Online user and Organic users or not as the result of paid campaigns.\n",
    "\n",
    "- Data: The datasets describe the behaviors of users in the form of different features. Each row equals to one user. The original data frame has a shape of approximately 235.000 rows with 25 distinct features.\n",
    "\n",
    "- Result: Among the four models, Gradient Descending Classifier and XGBoost appear to be the best model with the accuracy score on the training datasets of 82% and on the test datasets of 73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d1642a-f831-4880-9ce9-c17052910e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries and packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfff1499-8f45-4876-be5b-57ccbcd9a763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233169, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data from the datawarehouse - BigQuery\n",
    "sql = f\"\"\"\n",
    "WITH\n",
    "  userbase AS (\n",
    "  SELECT DISTINCT\n",
    "    small_device_id,\n",
    "    firstseen as first_seen,\n",
    "    distribution_channel,\n",
    "    MIN(major_version) AS version_to_use\n",
    "\n",
    "  FROM\n",
    "    `osp-bu-mobile.bi_playground.ofa_client_uplift`\n",
    "  WHERE\n",
    "    firstseen = DATE(_PARTITIONTIME) \n",
    "    AND country LIKE 'US'            \n",
    "    AND firstseen < '2022-08-01'\n",
    "    AND active\n",
    "  GROUP BY 1,2,3\n",
    "    ),\n",
    "\n",
    "day_of_use as (\n",
    "SELECT\n",
    "  small_device_id,\n",
    "  count(distinct DATE(_PARTITIONTIME) ) as DoU\n",
    "FROM\n",
    "    `osp-bu-mobile.bi_playground.ofa_client_uplift`\n",
    "WHERE\n",
    "  country LIKE 'US'            \n",
    "  AND firstseen < '2022-08-01'\n",
    "  AND  DATE(_PARTITIONTIME) BETWEEN firstseen AND DATE_ADD(firstseen, INTERVAL 150 DAY)\n",
    "  AND active\n",
    "GROUP BY 1\n",
    "\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  small_device_id,\n",
    "  CASE \n",
    "    WHEN version_to_use BETWEEN 0 AND 10 THEN '10'\n",
    "    WHEN version_to_use BETWEEN 11 AND 20 THEN '20'\n",
    "    WHEN version_to_use BETWEEN 21 AND 30 THEN '30'\n",
    "    WHEN version_to_use BETWEEN 31 AND 40 THEN '40'\n",
    "    WHEN version_to_use BETWEEN 41 AND 50 THEN '50'\n",
    "    WHEN version_to_use BETWEEN 51 AND 60 THEN '60'\n",
    "    WHEN version_to_use BETWEEN 61 AND 70 THEN '70'\n",
    "    WHEN version_to_use BETWEEN 71 AND 80 THEN '80'\n",
    "    \n",
    "  END AS version_to_use,\n",
    "  DoU as DOU,\n",
    "\n",
    "  SUM(page_loads_total)/DoU AS page_loads,\n",
    "  SUM(google_searches)/DoU as google_searches,\n",
    "\n",
    "  SUM(foreground_duration)/3600000/DoU as foreground_duration_hour,\n",
    "\n",
    "  SUM(ad_opportunities)/DoU as ad_opportunities,\n",
    "  SUM(ad_missed_opportunities)/DoU as ad_missed_opportunities,\n",
    "  SUM(ad_unique_clicks)/DoU as ad_unique_clicks,\n",
    "  SUM(ad_unique_impressions)/DoU as ad_unique_impressions,\n",
    "\n",
    "  SUM(sd_user_clicks)/DoU as sd_user_clicks,\n",
    "  SUM(sd_partner_clicks)/DoU as sd_partner_clicks, \n",
    "\n",
    "  SUM(ad_successful_requests)/DoU as ad_successful_requests,\n",
    "  SUM(ad_no_fill_requests)/DoU as ad_no_fill_requests,\n",
    "  SUM(ad_failed_requests)/DoU as ad_failed_requests,\n",
    "  SUM(news_sessions)/DoU as news_sessions, \n",
    "  SUM(news_article_interactions)/DoU as news_article_interactions,\n",
    "  SUM(start_page_views)/DoU as start_page_views,\n",
    "\n",
    "  MAX (CASE WHEN extended_stats is true then 1 ELSE 0 END) AS extended_stats,\n",
    "  MAX (CASE WHEN news_notifications_enabled is true then 1 ELSE 0 END) AS news_notifications_enabled,\n",
    "  MAX (CASE WHEN adblock_enabled is true then 1 ELSE 0 END) AS adblock_enabled,\n",
    "  MAX (CASE WHEN vpn_enabled is true then 1 ELSE 0 END) AS vpn_enabled, \n",
    "  MAX (CASE WHEN is_default_browser is true then 1 ELSE 0 END) AS is_default_browser,\n",
    "  MAX (CASE WHEN premium is true then 1 ELSE 0 END) AS premium, \n",
    "\n",
    "    CASE \n",
    "    WHEN userbase.distribution_channel = 'Organic' then 1\n",
    "    ELSE 0\n",
    "    END AS user_type\n",
    "\n",
    " FROM\n",
    "  `osp-bu-mobile.bi_playground.ofa_client_uplift`\n",
    "LEFT JOIN\n",
    "  userbase\n",
    "USING\n",
    "  (small_device_id)\n",
    "LEFT JOIN day_of_use\n",
    "USING (small_device_id)\n",
    "WHERE\n",
    "  DATE(_PARTITIONTIME) BETWEEN first_seen AND DATE_ADD(first_seen, INTERVAL 150 DAY)\n",
    "  AND active IS TRUE\n",
    "  AND public_release is TRUE\n",
    "GROUP BY 1,2,3,user_type\n",
    "ORDER BY 2,3\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_gbq(sql, project_id='osp-bu-mobile')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f899cf-2cfc-4d51-a98b-846f85531902",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864be31a-7485-4662-a951-68d0f885f9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T12:05:35.117190Z",
     "iopub.status.busy": "2023-03-31T12:05:35.116810Z",
     "iopub.status.idle": "2023-03-31T12:05:35.120387Z",
     "shell.execute_reply": "2023-03-31T12:05:35.119876Z",
     "shell.execute_reply.started": "2023-03-31T12:05:35.117165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removing extreme outliers manually (This is performed by drawing scatter plots in another script)\n",
    "\n",
    "df.drop(df[df['page_loads'] >= 2000].index, inplace = True)\n",
    "df.drop(df[df['google_searches'] >= 600].index, inplace = True)\n",
    "df.drop(df[df['ad_opportunities'] >= 500].index, inplace = True)\n",
    "df.drop(df[df['ad_missed_opportunities'] >= 500].index, inplace = True)\n",
    "df.drop(df[df['ad_unique_impressions'] >= 250].index, inplace = True)\n",
    "df.drop(df[df['sd_user_clicks'] >= 2000].index, inplace = True)\n",
    "df.drop(df[df['sd_partner_clicks'] >= 100].index, inplace = True)\n",
    "df.drop(df[df['ad_no_fill_requests'] >= 1000].index, inplace = True)\n",
    "df.drop(df[df['ad_failed_requests'] >= 1000].index, inplace = True)\n",
    "df.drop(df[df['ad_successful_requests'] >= 600].index, inplace = True)\n",
    "df.drop(df[df['news_article_interactions'] >= 60].index, inplace = True)\n",
    "df.drop(df[df['start_page_views'] >= 500].index, inplace = True)\n",
    "\n",
    "# Filling in missing values with 0\n",
    "df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105c1474-d59c-46b5-959a-6ea67c8fae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215788, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then removing outliers using function with 5 standard deviations\n",
    "\n",
    "# Define a function to remove outliers with 5 stds\n",
    "def remove_outliers(df, columns, n_std):\n",
    "    for col in columns:\n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "        df = df[(df[col] >= mean-(n_std*sd)) & (df[col] <= mean+(n_std*sd))]\n",
    "    return df\n",
    "\n",
    "# Apply the function the the numeric columns in the df\n",
    "numeric_features = df.columns[3:-7].to_list()\n",
    "\n",
    "df1 = remove_outliers(df, numeric_features, 5)\n",
    "df1.drop(columns = ['small_device_id'], inplace = True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f581aa-a81d-4986-8a7b-468fdc43761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205390, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating seperate dataframe for each version of the product.\n",
    "version50 = df1[df1['version_to_use'] == '50']\n",
    "version60 = df1[df1['version_to_use'] == '60']\n",
    "version70 = df1[df1['version_to_use'] == '70']\n",
    "\n",
    "version70.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ed5c735-115c-4ff7-a652-da85fe42de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape:  Counter({1: 158754, 0: 46636})\n"
     ]
    }
   ],
   "source": [
    "# Within the scope of this script, we only build classification model for \"Version 70\" \n",
    "y = version70.pop('user_type')\n",
    "X = version70.copy(deep=True)\n",
    "\n",
    "# The original balance of y\n",
    "print('Original dataset shape: ', Counter (y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1143b19c-929f-4ef4-9434-bb4e575b8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, test_size = .20, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc69933f-e717-4bc6-b6e3-c435ae15f550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numeric_features = numeric_features = df1.columns[2:-7].to_list()\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Define the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on the numeric features of training dataset\n",
    "scaler.fit(X_train_scaled[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b69ed72-164d-4bed-8b81-ca376544bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the training dataset\n",
    "X_train_scaled[numeric_features] = scaler.transform(X_train_scaled[numeric_features])\n",
    "\n",
    "# scale the test dataset\n",
    "X_test_scaled[numeric_features] = scaler.transform(X_test_scaled[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540e3c26-3c81-4bf5-9b86-987fa0668938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape Counter({1: 127003, 0: 37309})\n",
      "Testing dataset shape Counter({1: 31751, 0: 9327})\n"
     ]
    }
   ],
   "source": [
    "#splitting has preserved the class balance\n",
    "print('Training dataset shape %s' % Counter(y_train))\n",
    "print('Testing dataset shape %s' % Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed27b93f-24d1-4d87-a4db-38b403a7f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling by creating synthetic observations for Paid users\n",
    "upsampling = SMOTE()\n",
    "X_upsample, y_upsample = upsampling.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2d533-8b68-45a5-b4e4-dcd6bd257ac1",
   "metadata": {},
   "source": [
    "# MODEL 1: DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cb36d44-42dd-423b-b4c3-5691fc359cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 17,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_features': 12,\n",
       " 'max_depth': 28,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "# Specify the model\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "# Specify parameters range for the model\n",
    "DT_param = {'max_depth': np.arange(1,30),\n",
    "            'max_features': np.arange(2,15),\n",
    "            'min_samples_leaf': np.arange(1,20),\n",
    "            'min_samples_split': np.arange(2,20),\n",
    "            'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Apply RandomizedSearchCV to find the optimal parameters for the model\n",
    "DT_cv = RandomizedSearchCV(DT, param_distributions=DT_param, cv=10, n_iter=80, random_state=0)\n",
    "\n",
    "# DT_cv = GridSearchCV(DT, DT_param, cv=5, return_train_score = True)\n",
    "\n",
    "# Fitting the model to the rebalanced datasets\n",
    "DT_cv.fit(X_upsample, y_upsample)\n",
    "\n",
    "# Printing out the best parameters for the model\n",
    "DT_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8dfb63e-fe4b-4ddc-a94c-95dda4a01faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Decision Tree: 0.71158 (0.07023)\n"
     ]
    }
   ],
   "source": [
    "# DECISION TREE WITH THE BEST PARAMS\n",
    "\n",
    "# Running the new Decision Tree model with the best parameters gained from above\n",
    "DT_best = DecisionTreeClassifier(min_samples_leaf = DT_cv.best_params_['min_samples_leaf'],\n",
    "                                 min_samples_split = DT_cv.best_params_['min_samples_split'],\n",
    "                                 max_features = DT_cv.best_params_['max_features'],\n",
    "                                 max_depth = DT_cv.best_params_['max_depth'],\n",
    "                                 criterion = DT_cv.best_params_['criterion'],\n",
    "                                 random_state = 0)\n",
    "\n",
    "# Fitting the model to the datasets\n",
    "DT_best.fit(X_upsample, y_upsample)\n",
    "\n",
    "# Printing out the accuracy score of the Decision Tree model\n",
    "cv_scores = cross_validate(DT_best, X_upsample, y_upsample, scoring='accuracy', cv=10)\n",
    "score_mean = round(cv_scores['test_score'].mean(), 5)\n",
    "score_std = round(cv_scores['test_score'].std(), 5)\n",
    "print(f'Score of Decision Tree: {score_mean} ({score_std})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c26ef87-ce45-48ac-945e-9c6e64a2bf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6358391353035688"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score when running on test dataset\n",
    "y_model = DT_best.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_model)\n",
    "\n",
    "# Score of Decision Tree: 0.6358"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab10804-e1d7-4501-925f-433797d69ad0",
   "metadata": {},
   "source": [
    "# MODEL 2 : RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e841c1-0058-4870-8414-4350ae6b3605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:37:55.304228Z",
     "iopub.status.busy": "2023-03-31T10:37:55.303852Z",
     "iopub.status.idle": "2023-03-31T10:37:55.307363Z",
     "shell.execute_reply": "2023-03-31T10:37:55.306726Z",
     "shell.execute_reply.started": "2023-03-31T10:37:55.304206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "# Specify the Random Forest model\n",
    "RF = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Specify parameters range for the model\n",
    "RF_param = {'n_estimators': [20,50,100,150,200],\n",
    "            'max_depth': np.arange(1,30),\n",
    "            'max_features': np.arange(2,15),\n",
    "            'min_samples_leaf': np.arange(1,20),\n",
    "            'min_samples_split': np.arange(2,20),\n",
    "            'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Apply RandomizedSearchCV to find the optimal parameters for the model\n",
    "RF_cv = RandomizedSearchCV(RF, param_distributions=RF_param, cv=10, n_iter=40, random_state=0, verbose=3)\n",
    "\n",
    "# Fitting the model to the rebalanced datasets\n",
    "RF_cv.fit(X_upsample, y_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f7bd81c-635c-4a7a-908e-74d8fc06e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score = 0.79\n"
     ]
    }
   ],
   "source": [
    "# The best parameters chosen:\n",
    "RF_cv.best_params_\n",
    "print('''best score = {:.2f}'''.format(RF_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6e479ba-fe51-425e-bb09-75868ea7dbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 8,\n",
       " 'min_samples_leaf': 9,\n",
       " 'max_features': 7,\n",
       " 'max_depth': 29,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the best parameters for the model \n",
    "RF_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21a7a07b-f0ad-45f7-b452-5fa8e6813897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Random Forest: 0.7857 (0.09678)\n"
     ]
    }
   ],
   "source": [
    "#  Running the randomforest classifier with the best paras chosen\n",
    "\n",
    "RF_best = RandomForestClassifier(n_estimators=RF_cv.best_params_['n_estimators'], \n",
    "                                 max_features=RF_cv.best_params_['max_features'], \n",
    "                                 max_depth=RF_cv.best_params_['max_depth'], \n",
    "                                 criterion=RF_cv.best_params_['criterion'],\n",
    "                                 min_samples_leaf=RF_cv.best_params_['min_samples_leaf'],\n",
    "                                 min_samples_split=RF_cv.best_params_['min_samples_split'],\n",
    "                                 random_state = 0)\n",
    "\n",
    "# Fitting the model to the datasets\n",
    "\n",
    "RF_best.fit(X_upsample, y_upsample)\n",
    "cv_scores = cross_validate(RF_best, X_upsample, y_upsample, scoring='accuracy', cv=10) # note that cross validation = 10\n",
    "score_mean = round(cv_scores['test_score'].mean(), 5)\n",
    "score_std = round(cv_scores['test_score'].std(), 5)\n",
    "print(f'Score of Random Forest: {score_mean} ({score_std})')\n",
    "\n",
    "# Random Forest Classifier give an accuracy score of 0.7857 (0.09678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "403407c6-74f2-4b12-85a1-f56eaf3267dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7087492088222406"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for test dataset\n",
    "y_model = RF_best.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_model)\n",
    "\n",
    "# Accuracy score for test dataset: 0.7087492088222406"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437fa2a-fa52-4fcd-988a-5a695ffbecd9",
   "metadata": {},
   "source": [
    "# MODEL 3: Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f858df70-142a-49ba-a566-3b416f40cbd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:38:22.758440Z",
     "iopub.status.busy": "2023-03-31T10:38:22.758056Z",
     "iopub.status.idle": "2023-03-31T10:38:22.761456Z",
     "shell.execute_reply": "2023-03-31T10:38:22.760950Z",
     "shell.execute_reply.started": "2023-03-31T10:38:22.758417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier \n",
    "\n",
    "# Specify Gradient Boosting model\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# Specify parameters range for the model\n",
    "gbc_param = {'n_estimators': [20,50,100,150,200],\n",
    "             'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "             'subsample': np.arange(0.1, 1.1, 0.1),\n",
    "             'criterion': ['friedman_mse', 'squared_error'],\n",
    "             'min_samples_split': np.arange(2,20),\n",
    "             'min_samples_leaf': np.arange(1,20),\n",
    "             'max_depth': np.arange(1,30),\n",
    "             'max_features': np.arange(2,15)\n",
    "            }\n",
    "\n",
    "# Apply RandomizedSearchCV to find the optimal parameters for the model\n",
    "\n",
    "gbc_cv = RandomizedSearchCV(gbc, param_distributions=gbc_param, cv=10, n_iter=60, random_state=0, verbose=3)\n",
    "gbc_cv.fit(X_upsample, y_upsample)\n",
    "gbc_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0705eb7-7168-4989-8387-1f43c4495ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7000000000000001,\n",
       " 'n_estimators': 100,\n",
       " 'min_samples_split': 16,\n",
       " 'min_samples_leaf': 19,\n",
       " 'max_features': 6,\n",
       " 'max_depth': 29,\n",
       " 'learning_rate': 0.1,\n",
       " 'criterion': 'squared_error'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best parameters chosen:\n",
    "gbc_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67286320-91bd-48cd-8c4d-d05cbf2ecc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score = 0.82\n"
     ]
    }
   ],
   "source": [
    "print('''best score = {:.2f}'''.format(gbc_cv.best_score_))\n",
    "\n",
    "# best score = 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c3aefd-a9fc-4482-bb0e-59140402bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Gradient Boosting: 0.81914 (0.12273)\n"
     ]
    }
   ],
   "source": [
    "#  Running the randomforest classifier with the best paras chosen\n",
    "\n",
    "gbc_best = GradientBoostingClassifier(n_estimators=gbc_cv.best_params_['n_estimators'], \n",
    "                                      #loss=gbc_cv.best_params_['loss'], \n",
    "                                      subsample=gbc_cv.best_params_['subsample'], \n",
    "                                      criterion=gbc_cv.best_params_['criterion'],\n",
    "                                      learning_rate=gbc_cv.best_params_['learning_rate'],\n",
    "                                      max_features=gbc_cv.best_params_['max_features'], \n",
    "                                      max_depth=gbc_cv.best_params_['max_depth'], \n",
    "                                      min_samples_leaf=gbc_cv.best_params_['min_samples_leaf'],\n",
    "                                      min_samples_split=gbc_cv.best_params_['min_samples_split'],\n",
    "                                      random_state=0)\n",
    "\n",
    "# Fitting the model to the datasets\n",
    "gbc_best.fit(X_upsample, y_upsample)\n",
    "\n",
    "cv_scores = cross_validate(gbc_best, X_upsample, y_upsample, scoring='accuracy', cv=10)\n",
    "score_mean = round(cv_scores['test_score'].mean(), 5)\n",
    "score_std = round(cv_scores['test_score'].std(), 5)\n",
    "print(f'Score of Gradient Boosting: {score_mean} ({score_std})')\n",
    "\n",
    "# Score of Gradient Boosting: 0.81914 (0.12273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1665808a-c6ba-4671-949a-0aa0f5bd2287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252787380106139"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for test dataset\n",
    "y_model = gbc_best.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_model)\n",
    "\n",
    "# Accuracy score for test dataset: 0.7252787380106139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b077e-68ab-439e-9615-397bd5cd91be",
   "metadata": {},
   "source": [
    "# MODEL 4: XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7357048d-4f74-4db6-887d-688c4c424739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:38:55.204540Z",
     "iopub.status.busy": "2023-03-31T10:38:55.204164Z",
     "iopub.status.idle": "2023-03-31T10:38:55.207269Z",
     "shell.execute_reply": "2023-03-31T10:38:55.206751Z",
     "shell.execute_reply.started": "2023-03-31T10:38:55.204518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13090364-f370-4088-b37a-2c3ad7c27256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b739cc-68f7-4bce-a49b-07841800c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_upsample.drop(columns = ['version_to_use'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c75e30-24cd-4e07-a476-852a39d78425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:39:05.609262Z",
     "iopub.status.busy": "2023-03-31T10:39:05.608893Z",
     "iopub.status.idle": "2023-03-31T10:39:05.612209Z",
     "shell.execute_reply": "2023-03-31T10:39:05.611722Z",
     "shell.execute_reply.started": "2023-03-31T10:39:05.609240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoosting Classifier *try 1 - cv = 10, n_iter = 60\n",
    "\n",
    "# Specify the XGBClassifier model\n",
    "XGB = XGBClassifier(random_state=0)\n",
    "\n",
    "#Specify parameter range for the model\n",
    "XGB_param = {'n_estimators': [20,50,100,150,200,250],\n",
    "             'learning_rate': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "             'min_child_weight': np.arange(1,20),\n",
    "             'max_depth': np.arange(1,30),\n",
    "             'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "             'colsample_bytree': np.arange(0.08, 0.7)\n",
    "            }\n",
    "\n",
    "# Apply RandomizedSearchCV to find the optimal parameters for the model\n",
    "XGB_cv = RandomizedSearchCV(XGB, param_distributions=XGB_param, cv=10, n_iter=60, random_state=0, verbose=3)\n",
    "XGB_cv.fit(X_upsample, y_upsample)\n",
    "XGB_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99b472bc-f9fe-4aeb-8975-63df431162a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score = 0.79\n"
     ]
    }
   ],
   "source": [
    "print('''best score = {:.2f}'''.format(XGB_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03a1d16b-e45e-4900-a0ba-f5d591fe62f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of XGBoosting: 0.78665 (0.16331)\n"
     ]
    }
   ],
   "source": [
    "#  Running the randomforest classifier with the best paras chosen\n",
    "XGB_best = XGBClassifier(n_estimators=XGB_cv.best_params_['n_estimators'],                                     \n",
    "                                      learning_rate = XGB_cv.best_params_['learning_rate'],\n",
    "                                      min_child_weight = XGB_cv.best_params_['min_child_weight'], \n",
    "                                      max_depth = XGB_cv.best_params_['max_depth'], \n",
    "                                      gamma = XGB_cv.best_params_['gamma'],\n",
    "                                      colsample_bytree = XGB_cv.best_params_['colsample_bytree'],\n",
    "                                      random_state=0)\n",
    "\n",
    "# Fitting the model to the datasets\n",
    "XGB_best.fit(X_upsample, y_upsample)\n",
    "\n",
    "cv_scores = cross_validate(XGB_best, X_upsample, y_upsample, scoring='accuracy', cv=10)\n",
    "score_mean = round(cv_scores['test_score'].mean(), 5)\n",
    "score_std = round(cv_scores['test_score'].std(), 5)\n",
    "print(f'Score of XGBoosting: {score_mean} ({score_std})')\n",
    "\n",
    "# Score of Gradient Boosting: 0.81914 (0.12273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "992503ba-fa6e-4aad-b3ff-5837f4f351da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7163445153123327"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.drop(columns = ['version_to_use'], inplace = True)\n",
    "\n",
    "# Predict for test dataset\n",
    "y_model = XGB_best.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_model)\n",
    "\n",
    "# Accuracy score for test dataset: 0.7252787380106139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb52939-48d0-4248-8b38-8307e04389e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:39:21.628342Z",
     "iopub.status.busy": "2023-03-31T10:39:21.627966Z",
     "iopub.status.idle": "2023-03-31T10:39:21.631363Z",
     "shell.execute_reply": "2023-03-31T10:39:21.630794Z",
     "shell.execute_reply.started": "2023-03-31T10:39:21.628320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoosting Classifier * try 2 - cv = 10, n_iter = 100\n",
    "\n",
    "# Specify the XGBClassifier model\n",
    "XGB = XGBClassifier(random_state=0)\n",
    "\n",
    "#Specify parameter range for the model\n",
    "XGB_param = {'n_estimators': [20,50,100,150,200],\n",
    "             'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "             'min_child_weight': np.arange(1,20),\n",
    "             'max_depth': np.arange(1,30),\n",
    "             'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "             'colsample_bytree': np.arange(0.1, 0.8)\n",
    "            }\n",
    "\n",
    "# Apply RandomizedSearchCV to find the optimal parameters for the model\n",
    "XGB_cv = RandomizedSearchCV(XGB, param_distributions=XGB_param, cv=10, n_iter=100, random_state=0, verbose=3)\n",
    "XGB_cv.fit(X_upsample, y_upsample)\n",
    "XGB_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e538177-e1d3-4e77-9c4c-b0ba14368013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score = 0.80\n"
     ]
    }
   ],
   "source": [
    "print('''best score = {:.2f}'''.format(XGB_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da13a676-84e4-47eb-b3eb-1d1bde41f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of XGBoosting: 0.7974 (0.16521)\n"
     ]
    }
   ],
   "source": [
    "#  Running the randomforest classifier with the best paras chosen\n",
    "XGB_best = XGBClassifier(n_estimators=XGB_cv.best_params_['n_estimators'],                                     \n",
    "                                      learning_rate = XGB_cv.best_params_['learning_rate'],\n",
    "                                      min_child_weight = XGB_cv.best_params_['min_child_weight'], \n",
    "                                      max_depth = XGB_cv.best_params_['max_depth'], \n",
    "                                      gamma = XGB_cv.best_params_['gamma'],\n",
    "                                      colsample_bytree = XGB_cv.best_params_['colsample_bytree'],\n",
    "                                      random_state=0)\n",
    "\n",
    "# Fitting the model to the datasets\n",
    "XGB_best.fit(X_upsample, y_upsample)\n",
    "cv_scores = cross_validate(XGB_best, X_upsample, y_upsample, scoring='accuracy', cv=10)\n",
    "score_mean = round(cv_scores['test_score'].mean(), 5)\n",
    "score_std = round(cv_scores['test_score'].std(), 5)\n",
    "print(f'Score of XGBoosting: {score_mean} ({score_std})')\n",
    "\n",
    "# Score of Gradient Boosting: 0.81914 (0.12273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354dd32f-34a8-4a59-92a7-eeb3e2d63cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247675154583962"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for test dataset\n",
    "y_model = XGB_best.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_model)\n",
    "\n",
    "# Accuracy score for test dataset: 0.7252787380106139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8747e80-682f-4acd-8a1c-26b86923ebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
